<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine learning on Shawn T. O&#39;Neil</title>
    <link>/tags/machine-learning/</link>
    <description>Recent content in machine learning on Shawn T. O&#39;Neil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Feb 2019 00:00:00 +0000</lastBuildDate><atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Regression Trees &amp; Bagging (more functional R)</title>
      <link>/regression-trees/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/regression-trees/</guid>
      <description>I recently ran across this excellent article explaining gradient boosting in the context of regression trees. The article concludes by describing how the technique implements a gradient-descent process, but what I find most fascinating is the concept of “functional modeling”–building machine learning models from other models as building blocks.
This post explores that idea by implementing regression trees in base R (with a little visualization help from ggplot2, dplyr, and tidyr) with functional programming concepts, including a technique called bootstrap aggregating.</description>
    </item>
    
  </channel>
</rss>
